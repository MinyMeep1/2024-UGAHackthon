<!DOCTYPE html>
<html>
<head>
  <script src="face-api.js"></script>
  <script src="js/commons.js"></script>
  <script src="js/faceDetectionControls.js"></script>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
</head>
  <body>
    <html>

    <head>
      <meta charset="utf-8" />
      <link rel="stylesheet" href="globals.css" />
      <link rel="stylesheet" href="style.css" />
    </head>

    <body>
      <div class="menu-bar">
        <a href="http://localhost:3001/" id="about" class="text-wrapper">About</a>
        <a href="http://localhost:3000/webcam_face_detection" id="camera" class="div">Camera</a>
        <a href="http://localhost:3001/upload" id="upload" class="text-wrapper-2">Upload</a>
      </div>
    </body>

    </html>
    <div id="navbar"></div>
    <div class="center-content page-container">
      <div style="position: relative" class="margin">
        <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay muted playsinline></video>
        <canvas id="overlay" />
      </div>

  </body>

  <script>

    function dataURLToBlob(dataurl) {
      var arr = dataurl.split(','), mime = arr[0].match(/:(.*?);/)[1],
          bstr = atob(arr[1]), n = bstr.length, u8arr = new Uint8Array(n);
      while(n--){
          u8arr[n] = bstr.charCodeAt(n);
      }
      return new Blob([u8arr], {type:mime});
    }

    function blobToFile(blob, fileName){
      return new File([blob], fileName, { type: 'image/jpeg', lastModified: new Date() });
    }


    function captureImageFromVideo(videoEl, canvas) {
        console.log("okay");
        canvas.getContext('2d').drawImage(videoEl, 0, 0, canvas.width, canvas.height);
        const imageDataUrl = canvas.toDataURL('image/jpeg');
        console.log(imageDataUrl);
        const imageBlob = dataURLToBlob(imageDataUrl);

        const timestamp = Date.now();
        const fileName = `image_${timestamp}.jpg`;

        const imageFile = blobToFile(imageBlob, fileName); 

        let formData = new FormData();
        formData.append('file', imageFile); 
        fetch('http://127.0.0.1:5000/send_image', { // Your API endpoint
            method: 'POST',
            body: formData
        })
        .then(response => response.json())
        .then(data => {
            console.log(data); // Handle success
        })
        .catch(error => {
            console.error(error); // Handle errors
        });
    }

    let forwardTimes = []

    function updateTimeStats(timeInMs) {
      forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
      const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
      $('#time').val(`${Math.round(avgTimeInMs)} ms`)
      $('#fps').val(`${faceapi.utils.round(1000 / avgTimeInMs)}`)
    }

    let captureInterval;
    let isFaceDetected = false;

    async function onPlay() {
      const videoEl = $('#inputVideo').get(0)
      const canvas = $('#overlay').get(0);

      if(videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
        return setTimeout(() => onPlay())


      const options = getFaceDetectorOptions()
      const ts = Date.now()
      const result = await faceapi.detectSingleFace(videoEl, options)

      updateTimeStats(Date.now() - ts)

    if (result) {
        if (!isFaceDetected) {
            isFaceDetected = true;
            // Start capturing images every 5 seconds
            captureInterval = setInterval(() => captureImageFromVideo(videoEl, canvas), 5000);
        }
        const dims = faceapi.matchDimensions(canvas, videoEl, true);
        faceapi.draw.drawDetections(canvas, faceapi.resizeResults(result, dims));
    } else {
        if (isFaceDetected) {
            isFaceDetected = false;
            // Stop capturing images if no face is detected
            clearInterval(captureInterval);
        }
    }

      setTimeout(() => onPlay())
    }

    async function run() {
      // load face detection model
      await changeFaceDetector(TINY_FACE_DETECTOR)
      changeInputSize(128)

      // try to access users webcam and stream the images
      // to the video element
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
      const videoEl = $('#inputVideo').get(0)
      videoEl.srcObject = stream
    }

    function updateResults() {}

    $(document).ready(function() {
      renderNavBar('#navbar', 'webcam_face_detection')
      initFaceDetectionControls()
      run()
    })
  </script>
</body>
</html>